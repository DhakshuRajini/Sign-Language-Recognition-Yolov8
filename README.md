# ğŸ§  Sign-Language-Recognition-YOLOv8

A real-time sign language recognition system built using **YOLOv8**, **MediaPipe**, **OpenCV**, and **Flask**. This project converts hand gestures into **text and speech**, aiming to assist individuals with hearing or speech impairments.

---

## ğŸ“˜ About This Project

This project is a real-time Sign Language Recognition system developed using a combination of YOLOv8, MediaPipe, OpenCV, and Flask. The main goal of the project is to provide an effective and accessible way for individuals with hearing or speech impairments to communicate with others by recognizing and translating sign language gestures into both text and speech.

The system works by capturing hand gestures either from a live webcam feed or from uploaded images. YOLOv8 is used for detecting hands, while MediaPipe provides accurate hand landmark tracking. These are processed to identify the specific sign being made. Once a gesture is recognized, it is displayed as text and also converted to speech using the `pyttsx3` library.

The project features a simple web interface using Flask, where users can interact with the system via webcam or image uploads. It serves as an innovative and socially impactful application of AI and computer vision.

---

## ğŸ¯ Project Goals

- Build a system that can recognize hand signs in real-time using a webcam or uploaded images.
- Translate recognized gestures into text and spoken output.
- Provide an accessible tool to bridge communication gaps for the speech- and hearing-impaired.

---

## ğŸ› ï¸ Tools & Technologies Used

- **YOLOv8 (Ultralytics)** â€“ for object (hand) detection  
- **MediaPipe (Google)** â€“ for real-time hand landmark tracking  
- **OpenCV** â€“ for image processing and webcam access  
- **Flask** â€“ lightweight Python web framework  
- **HTML / CSS / JavaScript** â€“ for the web front-end  
- **pyttsx3** â€“ for converting recognized text to speech  
- **NumPy, Pillow** â€“ supporting libraries for array and image operations

---

## âœ¨ Key Features

- ğŸ”´ Real-time sign language detection via webcam  
- ğŸ–¼ï¸ Upload image to detect signs offline  
- ğŸ“ƒ Output text from recognized gestures  
- ğŸ”Š Audio feedback using text-to-speech  
- ğŸŒ Clean and simple web interface

---

## ğŸš€ How to Run the Project Locally

1. **Install dependencies**:

```bash
pip install -r requirements.txt
python app.py
http://127.0.0.1:5000

ğŸ§¾ Project Structure
SignLanguageRecognition/
â”œâ”€â”€ app.py                  # Main Flask server
â”œâ”€â”€ check.py                # YOLOv8 + MediaPipe logic
â”œâ”€â”€ requirements.txt        # Required Python libraries
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ result.html
â”œâ”€â”€ static/
â”‚   â””â”€â”€ uploads/            # Uploaded images
â”œâ”€â”€ README.md               # Project documentation
